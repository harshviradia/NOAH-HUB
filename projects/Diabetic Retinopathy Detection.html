<!DOCTYPE html>
<html
	class="gap-outside side-header-hamburguer-sidebar side-header-hamburguer-sidebar-right side-header-above side-header-right-no-reverse">

<head>

	<!-- Basic -->
	<meta charset="utf-8">
	<meta http-equiv="X-UA-Compatible" content="IE=edge">

	<title>Diabetic Retinopathy</title>

	<meta name="description" content="NOAH HUB TEMPLATE">

	<!-- Favicon -->
	<link rel="shortcut icon" href="../img/logo.webp" type="image/x-icon" />
	<link rel="apple-touch-icon" href="../img/logo.webp">

	<!-- Mobile Metas -->
	<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1.0, shrink-to-fit=no">

	<!-- Web Fonts  -->
	<link id="googleFonts"
		href="https://fonts.googleapis.com/css?family=Poppins:300,400,500,600,700,800%7CShadows+Into+Light%7CPlayfair+Display:400&display=swap"
		rel="stylesheet" type="text/css">

	<!-- Vendor CSS -->
	<link rel="stylesheet" href="../vendor/bootstrap/css/bootstrap.min.css">
	<link rel="stylesheet" href="../vendor/fontawesome-free/css/all.min.css">
	<link rel="stylesheet" href="../vendor/animate/animate.compat.css">
	<link rel="stylesheet" href="../vendor/simple-line-icons/css/simple-line-icons.min.css">
	<link rel="stylesheet" href="../vendor/owl.carousel/assets/owl.carousel.min.css">
	<link rel="stylesheet" href="../vendor/owl.carousel/assets/owl.theme.default.min.css">
	<link rel="stylesheet" href="../vendor/magnific-popup/magnific-popup.min.css">

	<!-- Theme CSS -->
	<link rel="stylesheet" href="../css/theme.css">
	<link rel="stylesheet" href="../css/theme-elements.css">
	<link rel="stylesheet" href="../css/theme-blog.css">
	<link rel="stylesheet" href="../css/theme-shop.css">

	<!-- Skin CSS -->
	<link id="skinCSS" rel="stylesheet" href="../css/skins/skin-corporate-18.css">

	<!-- Theme Custom CSS -->
	<link rel="stylesheet" href="../css/custom.css">

	<!-- Head Libs -->
	<script src="../vendor/modernizr/modernizr.min.js"></script>

</head>

<body data-plugin-page-transition>
	<div class="body">
		<div class="sticky-wrapper sticky-wrapper-transparent sticky-wrapper-effect-1 sticky-wrapper-border-bottom"
			data-plugin-sticky data-plugin-options="{'minWidth': 0, 'stickyStartEffectAt': 100, 'padding': {'top': 0}}">
			<div class="sticky-body">
				<div class="container-fluid">
					<div class="row align-items-center">
						<div class="col-9">
							<div class="py-4 ps-2">
								<a href="../index.html">
									<img alt="Porto" width="100" height="48" data-change-src="../img/nav logo.webp"
										src="../img/nav logo.webp">
								</a>
							</div>
						</div>
					</div>
				</div>
			</div>
		</div>


		<div role="main" class="main">
			<div class="owl-carousel owl-carousel-light owl-carousel-light-init-fadeIn owl-theme manual bg-color-light-scale-1 dots-inside dots-horizontal-center show-dots-hover show-dots-xs nav-style-1 nav-primary nav-inside nav-inside-plus nav-lg nav-font-size-md show-nav-hover mb-0"
				data-plugin-options="{'autoplayTimeout': 9000}" style="height: calc( 100vh - 25px );">
				<div class="owl-stage-outer">
					<div class="owl-stage">

						<!-- Carousel Slide 1 -->
						<section class="section border-0 video overlay overlay-show overlay-op-8 m-0"
							data-video-path="../img/projects/SGP4/hero" data-plugin-video-background
							data-plugin-options="{'posterType': 'jpg', 'position': '50% 50%'}" style="height: 100vh;">
							<div class="container position-relative z-index-3 h-100">
								<div class="row align-items-center h-100">
									<div class="col">
										<div class="d-flex flex-column align-items-center justify-content-center h-100">

											<p class="text-10 text-color-light font-weight-light opacity-7 mb-0"
												data-plugin-animated-letters
												data-plugin-options="{'startDelay': 1000, 'minWindowWidth': 0}"
												style="color: white;"><strong>Depression Detection using NLP</strong>
											</p>
										</div>
									</div>
								</div>
								<a href="#main"
									class="slider-scroll-button position-absolute bottom-10 left-50pct transform3dx-n50"
									data-hash data-hash-offset="80">Sroll To Bottom</a>
							</div>
						</section>


					</div>
				</div>
			</div>

			<div class="home-intro bg-color-grey-scale-1 my-0 py-0" id="home-intro">
				<div class="container">

					<div class="row justify-content-center">
						<div class="col-lg-8 appear-animation" data-appear-animation="fadeIn"
							data-appear-animation-delay="200">
							<div class="card bg-transparent border-0">
								<div class="card-body my-2">
									<a class="text-decoration-none lightbox"
										href=" https://drive.google.com/file/d/1Yc_wBAaWp0CF3bH-E9aYHKYQOx7iQiiw/view?usp=sharing"
										data-plugin-options="{'type':'iframe'}">
										<div class="feature-box align-items-center">
											<div class="feature-box-icon bg-color-light text-8">
												<i class="fas fa-play text-color-dark text-1"></i>
											</div>
											<div class="feature-box-info">
												<p class="mb-0 text-color-dark font-weight-bold negative-ls-1">
													We are sure you will enjoy watch our video.
												</p>
											</div>
										</div>
									</a>
								</div>
							</div>
						</div>
					</div>

				</div>
			</div>


			<section id="who-we-are" class="section section-height-3 bg-transparent border-0 m-0">
				<div class="container py-4">
					<div class="row align-items-center justify-content-center">
						<div class="col-lg-6 pe-lg-5 mb-5 mb-lg-0">
							<div class="overflow-hidden">
							</div>
							<div class="overflow-hidden mb-3">
								<h3 class="text-color-dark font-weight-bold text-transform-none line-height-1 text-10 mb-0 appear-animation"
									data-appear-animation="maskUp" data-appear-animation-delay="200">ABSTARCT</h3>
							</div>
							<p class="text-3-5 appear-animation" data-appear-animation="fadeInUpShorter"
								style="text-align: justify;" data-appear-animation-delay="600">Over a period of time one
								of the consequences of diabetes could be damage to the retina of the eye causing
								problems with eyesight the condition is as known as diabetic retinopathy. It is common
								complication of diabetes. To understand diabetic retinopathy let’s have look in the
								below image. The part of the of the front of the eye is called the cornea, the light
								passes through the cornea and hits the lens, the lens focuses the light on the back of
								the eye onto a light-sensitive lining called a retina, before exiting the back of the
								eye through the optic nerve there are blood vessels that travel through the retina and
								exit the back of the eye through the middle of the optic nerve. Over time uncontrolled
								high sugar levels can affect this blood vessels as a result, they might leak blood or
								any other fluids causing swelling and damage to the retina. In the early stages of
								diabetic retinopathy there are no symptoms or very mild symptoms that may go unnoticed
								as diabetic retinopathy progresses the following signs and symptoms may occur. Floaters
								on your filed of vision. Floaters are tiny dark specks or strings that move around the
								rear chamber of the eye causing you to see spots. This kind of difficulty faced same as
								night. Pain or pressure in one eye or both eyes. Usually both eyes get affected by
								diabetic retinopathy. Through the survey approximately 1 out of 10 adults have diabetes
								and 1 out 3 have diabetic retinopathy. It’s important to find out if anyone has diabetic
								retinopathy early and treat it. If left untreated it eventually leads to blindness. If
								anyone is diabetic so they can help or prevent or slow the development of diabetic
								retinopathy by taking prescribed medication, sticking the diet, exercising regularly,
								controlling high blood pressure or high cholesterol, avoid alcohol and smoking, hence
								timely diagnosis and regular eye check-up’s along with optimal control of blood sugar
								through diet, exercise and medication is of most importance to effectively manage
								diabetic retinopathy</p>
						</div>
						<div class="col-md-6 order-1 order-md-2 text-center text-md-start mb-5 mb-md-0">
							<a href="#"
								class="btn btn-dark font-weight-semibold rounded-0 px-5 btn-py-2 text-2">Technical
								Paper</a>
						</div>

						<div class="col-5 col-sm-7 col-md-12 col-lg-6 text-center">
							<div class="position-relative d-inline-flex">
								<a style="text-align: center;"><img src="../img/projects/SGP5/img-1.webp" width="80%"
										height="80%" class="img-fluid" alt="" /></a>
							</div>
						</div>
					</div>
				</div>
			</section>

			<section id="who-we-are" class="section section-height-3 bg-transparent border-0 m-0">
				<div class="container py-4">
					<div class="row align-items-center justify-content-center">
						<!-- <div class="col-5 col-sm-7 col-md-12 col-lg-6 text-center">
							<div class="position-relative d-inline-flex">
								<a style="text-align: center;"><img src="../img/projects/SGP5/library.webp"
										class="img-fluid" alt="" /></a>
							</div>
						</div> -->
						<div class="col-lg-12 pe-lg-3 mb-5 mb-lg-0">
							<div class="overflow-hidden">
							</div>
							<div class="overflow-hidden mb-3">
								<h3 class="text-color-dark font-weight-bold text-transform-none line-height-1 text-10 mb-0 appear-animation"
									data-appear-animation="maskUp" data-appear-animation-delay="200">Method applied for
									Diabetic Retinopathy</h3>
							</div>
							<p class="text-3-5 appear-animation" data-appear-animation="fadeInUpShorter"
								style="text-align: justify;" data-appear-animation-delay="600">The study was approved by
								the Ethics Committee of Shanghai Sixth People’s Hospital and conducted in accordance
								with the Declaration of Helsinki. Informed consent was obtained from participants. In
								the SIM project, retinal photographs were captured using desktop retinal cameras from
								Canon, Topcon, and ZEISS (Supplementary Table 1). All the fundus cameras were qualified
								by the organizer to ensure enough quality for DR grading. The operators of the cameras
								had all received standard training and the images were read by a centered reading group
								consisting of 133 certified ophthalmologists. The members in the reading group underwent
								training by fundus specialists and passed the tests. Original retinal images were
								uploaded to the online platform, and the images of each eye were assigned separately to
								two authorized ophthalmologists. They labeled the images using an online reading
								platform and gave the graded diagnosis of DR (Supplementary Fig. 2). The third
								ophthalmologist who served as the senior supervisor confirmed or corrected when the
								diagnostic results were contradictory. The final grading result was dependent on the
								consistency within these three ophthalmologists. At least 20% of the grading results
								would be randomly re-read to check the consistency. The total eligibility rate of
								spot-check was equal to or greater than 90%. If the reading group encountered difficult
								cases, they could apply for consultation from superior medical institutions. The overall
								disagreement rate in the SIM dataset was 18.9%. The primary cause of the diagnostic
								divergence was the decision between mild NPDR and non-DR. For retinal lesion annotation,
								each fundus image was annotated by two ophthalmologists. For each type of lesion, two
								ophthalmologists generated two lesion annotations, respectively. We considered the two
								annotations to be valid if the IoU between them was greater than 0.85. Otherwise, a
								senior supervisor would check the annotations and give feedback to provide guidance. The
								image would be re-annotated by the two ophthalmologists until the IoU was larger than
								0.85. Finally, we took the union of valid annotations as final ground truth segmentation
								annotation. DR severity was graded into five levels (non-DR, mild NPDR, moderate NPDR,
								severe NPDR, or PDR, respectively), according to the International Clinical Diabetic
								Retinopathy Disease Severity Scale (AAO, October 2002)53. Mild NPDR was defined as the
								presence of microaneurysms only. Moderate NPDR was defined as more than just
								microaneurysms but less than severe NPDR, presenting CWS, hard exudates, and/or retinal
								hemorrhages. Severe NPDR was defined as any of the following: more than 20 intraretinal
								hemorrhages in each of the 4 quadrants; definite venous beading in 2+ quadrants;
								prominent intraretinal microvascular abnormalities (IRMA) in 1+ quadrant, and no signs
								of PDR. PDR was defined as one or more of the following: neovascularization,
								vitreous/preretinal hemorrhage53. DME was diagnosed if hard exudates were detected
								within 500 μm of the macular center according to the standard of the Early Treatment for
								Diabetic Retinopathy study54. Referable DR was defined as moderate NPDR or worse, DME,
								or both. Based on the guidelines for image acquisition and interpretation of diabetic
								retinopathy screening in China55, the image quality was graded according to standards
								defined in terms of three quality factors, artifacts, clarity, and field definition56,
								as listed in Table 5. The total score was equal to the score for clarity plus the score
								for field definition and minus the score for artifacts. A total score less than 12 was
								considered as ungradable. </p>

						</div>
					</div>
				</div>
			</section>

			<section id="who-we-are" class="section section-height-3 bg-transparent border-0 m-0">
				<div class="container py-4">
					<div class="row align-items-center justify-content-center">

						<div class="col-lg-12 pe-lg-5 mb-5 mb-lg-0">
							<div class="overflow-hidden">
							</div>
							<div class="overflow-hidden mb-3">
								<h3 class="text-color-dark font-weight-bold text-transform-none line-height-1 text-10 mb-0 appear-animation"
									data-appear-animation="maskUp" data-appear-animation-delay="200">Architecture of the
									DeepDR system</h3>
							</div>
							<p class="text-3-5 appear-animation" data-appear-animation="fadeInUpShorter"
								style="text-align: justify;" data-appear-animation-delay="600">
								The DeepDR system had three sub-networks: image quality assessment sub-network,
								lesion-aware sub-network, and DR grading sub-network. Those sub-networks were developed
								based on ResNet41 and Mask-RCNN57. Both ResNet and Mask-RCNN could be divided into two
								parts: (1) feature extractor, which took images as input and output features, (2)
								task-specific header, which took the features as input and generated task-specific
								outputs (i.e., classification or segmentation). Specifically, we chose to use the
								Mask-RCNN and ResNet with the same feature extractor architecture, so the feature
								extractor of one sub-network can be easily transferred to another.

								The quality assessment sub-network can identify overall quality including gradability,
								artifacts, clarity, and field issues for the input images. To train the image quality
								assessment sub-network effectively, we initialized a ResNet with weights pre-trained on
								ImageNet and pre-trained the ResNet to form the DR base network. We utilized the weights
								of the convolution layers in the pre-trained DR base network to initialize the feature
								extractor of the image quality assessment sub-network. We assessed image quality in
								terms of multiple factors to determine if: (a) the artifact covered the macular area or
								the area of artifact was larger than a quadrant of the retinal image; (b) only Level II
								or wider vascular arch and obvious lesions could be identified (Level II vascular arch
								was defined as the veins deriving from the first bifurcation); (c) no optic disc or
								macula was contained in the image; and (d) the image was not gradable.

								The lesion-aware sub-network can generate lesion presence and lesion segmentation masks
								of the input images. There were two modules in our lesion-aware sub-network: one was the
								lesion detection module and the other was the lesion segmentation module. The lesion
								detection module was a binary classifier that predicted whether any kind of lesions
								exist in a quadrant of the retinal image, as shown in Supplementary Fig. 3. The lesion
								segmentation module generated mask images to identify different lesions existing in the
								retinal images, as shown in Fig. 3B. We used ResNet and Mask-RCNN to form the lesion
								detection module and lesion segmentation module, respectively. Then we transferred the
								pre-trained DR base network to the lesion detection module by initializing the feature
								extractor of lesion detection module using the feature extractor of pre-trained DR base
								network, followed by fine-tuning the lesion detection module. Then we initialized the
								feature extractor of lesion segmentation module by reusing the feature extractor of the
								lesion detection module. The feature extractor layers of the lesion segmentation module
								were then fixed, and the rest of the layers of the module were updated during training.
								Non-maximum suppression was used in our lesion segmentation sub-module to select the
								bounding box with the highest objectiveness score from multiple predicted bounding
								boxes. Specifically, we first selected the bounding box with the highest objectiveness
								score, and then compared the IoU of this bounding box with other bounding boxes and
								removed the bounding boxes with IoU > 0.5. Finally, we moved to the next box with the
								highest objectiveness score and repeated until all boxes were either removed or
								selected.

								The DR grading sub-network can fuse features from lesion-aware network and generate
								final DR grading results. To retain as much lesion information from the original retinal
								image as possible, we combined the pre-trained DR base network with the feature
								extractor of the lesion segmentation module in order to capture more detailed lesion
								features for DR grading. Then the weights in the extractors of DR grading sub-network
								were fixed, and the classification header of sub-network was updated during training.

								The transfer learning assisted multi-task network was developed in our DeepDR
								architecture to improve the performance of DR grading based on lesion detection and
								segmentation. Due to the fact that DR grading inherently relies on the global presences
								of retinal lesions that contain multi-scale local texture and structures, the central
								feature of our multi-task learning method was designed to extract multi-scale features
								encoding local textures and structures of retinal lesions, where the transfer learning
								was used to improve the performance of DR grading task. Meanwhile, we used
								hard-parameter sharing in lesion-aware sub-network, and all the layers in the feature
								extractors of ResNet and Mask-RCNN are shared. Using hard-parameter sharing was
								important to reduce the risk of overfitting58 due to the limited number of lesion
								segmentation labels. Besides, sharing the pre-trained weights can facilitate the
								training of both lesion detection task and lesion segmentation task.
							</p>
						</div>
					</div>
				</div>
			</section>
			<!--  -->
			<!--  -->
			<!--  -->
			<!--  -->

			<section id="who-we-are" class="section section-height-3 bg-transparent border-0 m-0">
				<div class="container py-4">
					<div class="row align-items-center justify-content-center">

						<div class="col-lg-12 pe-lg-5 mb-5 mb-lg-0">
							<div class="overflow-hidden">
							</div>
							<div class="overflow-hidden mb-3">
								<h3 class="text-color-dark font-weight-bold text-transform-none line-height-1 text-10 mb-0 appear-animation"
									data-appear-animation="maskUp" data-appear-animation-delay="200">Image processing
									and analysis</h3>
							</div>
							<p class="text-3-5 appear-animation" data-appear-animation="fadeInUpShorter"
								style="text-align: justify;" data-appear-animation-delay="600">As we can see, there is
								class imbalance in the training data-set with most cases having value of ‘0’ and least
								in ‘1’ and ‘3’ classes.
								<br>
							<div class="col-12 col-sm-7 col-md-12 col-lg-6 text-center">
								<div class="position-relative d-inline-flex">
									<a style="text-align: center;"><img src="../img/projects/SGP6/1.webp" width="100%"
											height="100%" class="img-fluid" alt="" /></a>
								</div>
							</div>
							These are basically eye retina images taken using fundus photography. As we can see, images
							contain artifacts, some of them are out of focus, underexposed, or overexposed etc. Also,
							some of the images have low brightness and low lightning conditions thus making it difficult
							to assess the difference between the images. Below is a sample retina image of an eye that
							would contain diabetic retinopathy.

						</div>

						<div class="col-12 col-sm-7 col-md-12 col-lg-6 text-center">
							<div class="position-relative d-inline-flex">
								<a style="text-align: center;"><img src="../img/projects/SGP6/2.webp" width="100%"
										height="100%" class="img-fluid" alt="" /></a>
							</div>
						</div>
						<br>
						<br>
						<div class="col-12 col-sm-7 col-md-12 col-lg-6 text-center">
							<div class="position-relative d-inline-flex">
								<a style="text-align: center;"><img src="../img/projects/SGP6/3.webp" width="100%"
										height="100%" class="img-fluid" alt="" /></a>
							</div>
						</div>
						<br>

						As we can see, we are trying to spot those hemorrhages/exudates etc. in the higher classes which
						have DR. To adjust for the images and make more clearer images so as to enable the model to
						learn features more effectively, we will carry out some image processing techniques using OpenCV
						library in python (cv2).
						We can apply Gaussian blur to bring out distinctive features in the images. In Gaussian Blur
						operation, the image is convolved with a Gaussian filter which is a low-pass filter that removes
						the high-frequency components.

						<div class="col-12 col-sm-7 col-md-12 col-lg-6 text-center">
							<div class="position-relative d-inline-flex">
								<a style="text-align: center;"><img src="../img/projects/SGP6/4.webp" width="100%"
										height="100%" class="img-fluid" alt="" /></a>
							</div>
						</div>

						As we can see, we are much more clearly able to see the distinctive patterns in the imgaes
						now.Here are the image processing applied on 15 image samples.

						<div class="col-12 col-sm-7 col-md-12 col-lg-6 text-center">
							<div class="position-relative d-inline-flex">
								<a style="text-align: center;"><img src="../img/projects/SGP6/5.webp" width="100%"
										height="100%" class="img-fluid" alt="" /></a>
							</div>
						</div>

						<div class="col-12 col-sm-7 col-md-12 col-lg-6 text-center">
							<div class="position-relative d-inline-flex">
								<a style="text-align: center;"><img src="../img/projects/SGP6/6.webp" width="100%"
										height="100%" class="img-fluid" alt="" /></a>
							</div>
						</div>


					</div>
				</div>
			</section>
			<!--  -->
			<!--  -->
			<!--  -->
			<!--  -->
			<!--  -->

			<section id="who-we-are" class="section section-height-3 bg-transparent border-0 m-0">
				<div class="container py-4">
					<div class="row align-items-center justify-content-center">
						<div class="col-5 col-sm-7 col-md-12 col-lg-6 text-center">
							<div class="position-relative d-inline-flex">
								<a style="text-align: center;"><img src="../img/projects/SGP6/7.webp" width="80%"
										height="80%" class="img-fluid" alt="" /></a>
							</div>
						</div>
						<div class="col-lg-6 pe-lg-5 mb-5 mb-lg-0">
							<div class="overflow-hidden">
							</div>
							<div class="overflow-hidden mb-3">
								<h3 class="text-color-dark font-weight-bold text-transform-none line-height-1 text-10 mb-0 appear-animation"
									data-appear-animation="maskUp" data-appear-animation-delay="200">Model Architecture
									Used</h3>
							</div>
							<p class="text-3-5 appear-animation" data-appear-animation="fadeInUpShorter"
								style="text-align: justify;" data-appear-animation-delay="600">As we can see below, the
								Research paper uses a Multi Task learning Model (it parallely does training for
								Regression, Classification, Ordinal Regression). This way it can use single Model and
								since first layers would anyway learn similar features, this architecture is implemented
								to reduce training time (instead of training 3 seperate models). For the Encoder part,
								we could use any Existing CNN architecture — ResNet50, EfficientNetB4, EfficientNetB5
								(and ensemble these).
							</p>
						</div>


					</div>
				</div>
			</section>

			<section id="dev">
				<div class="container appear-animation" data-appear-animation="fadeInUpShorter"
					data-appear-animation-delay="300">
					<div class="container py-5 my-3">
						<div class="row justify-content-center text-center">
							<div class="col">
								<h4 class="text-11 font-weight-extra-bold mb-1 line-height-2">DEVLOPERS</h4>
							</div>
						</div>
					</div>
					<div class="row py-5 my-5">
						<div class="col-md-6 order-2 order-md-1 text-center text-md-start">
							<div class="owl-carousel owl-theme nav-style-1 nav-center-images-only stage-margin mb-0"
								data-plugin-options="{'responsive': {'576': {'items': 1}, '768': {'items': 1}, '992': {'items': 2}, '1200': {'items': 2}}, 'margin': 25, 'loop': false, 'nav': true, 'dots': false, 'stagePadding': 40}">
								<div>
									<img class="img-fluid rounded-0 mb-4" src="../img/devloper/harsh.webp" alt="" />
									<h3 class="font-weight-bold text-color-dark text-4 mb-0">Harsh Viradia</h3>
									<div class="col-md-2 col-lg-6">
										<h5 class="text-3 mb-3">Connect with</h5>
										<ul class="social-icons">
											<li class="social-icons-linkedin"><a
													href="https://www.linkedin.com/in/harsh-viradia-3a5386191/"
													target="_blank" title="Linkedin"><i
														class="fab fa-linkedin-in"></i></a></li>
											<li class="social-icons-instagram"><a
													href="https://www.instagram.com/harsh._viradia/" target="_blank"
													title="Instagram"><i class="fab fa-instagram"></i></a></li>
											<li class="social-icons-github"><a href="https://github.com/harshviradia"
													target="_blank" title="Github"><i class="fab fa-github"></i></a>
											</li>
										</ul>
									</div>
								</div>
							</div>
						</div>

						<div class="col-md-6 order-2 order-md-1 text-center text-md-start">
							<div class="owl-carousel owl-theme nav-style-1 nav-center-images-only stage-margin mb-0"
								data-plugin-options="{'responsive': {'576': {'items': 1}, '768': {'items': 1}, '992': {'items': 2}, '1200': {'items': 2}}, 'margin': 25, 'loop': false, 'nav': true, 'dots': false, 'stagePadding': 40}">
								<div>
									<img class="img-fluid rounded-0 mb-4" src="../img/devloper/jhanvi.webp" alt="" />
									<h3 class="font-weight-bold text-color-dark text-4 mb-0">Jhanvi Shah</h3>
									<div class="col-md-2 col-lg-6">
										<h5 class="text-3 mb-3">Connect with</h5>
										<ul class="social-icons">
											<li class="social-icons-linkedin"><a
													href="https://www.linkedin.com/in/jhanvi-shah-99b98b165/"
													target="_blank" title="Linkedin"><i
														class="fab fa-linkedin-in"></i></a></li>
											<li class="social-icons-instagram"><a
													href="https://www.instagram.com/jhanvi_shah01/" target="_blank"
													title="Instagram"><i class="fab fa-instagram"></i></a></li>
											<li class="social-icons-github"><a href="https://github.com/Jhanvi2001"
													target="_blank" title="Github"><i class="fab fa-github"></i></a>
											</li>
										</ul>
									</div>
								</div>
							</div>
						</div>
					</div>
				</div>
			</section>

		</div>



		<!-- Vendor -->
		<script src="../vendor/jquery/jquery.min.js"></script>
		<script src="../vendor/jquery.appear/jquery.appear.min.js"></script>
		<script src="../vendor/jquery.easing/jquery.easing.min.js"></script>
		<script src="../vendor/jquery.cookie/jquery.cookie.min.js"></script>
		<script src="../vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
		<script src="../vendor/jquery.validation/jquery.validate.min.js"></script>
		<script src="../vendor/jquery.easy-pie-chart/jquery.easypiechart.min.js"></script>
		<script src="../vendor/jquery.gmap/jquery.gmap.min.js"></script>
		<script src="../vendor/lazysizes/lazysizes.min.js"></script>
		<script src="../vendor/isotope/jquery.isotope.min.js"></script>
		<script src="../vendor/owl.carousel/owl.carousel.min.js"></script>
		<script src="../vendor/magnific-popup/jquery.magnific-popup.min.js"></script>
		<script src="../vendor/vide/jquery.vide.min.js"></script>
		<script src="../vendor/vivus/vivus.min.js"></script>

		<!-- Theme Base, Components and Settings -->
		<script src="../js/theme.js"></script>

		<!-- Revolution Slider Addon - Typewriter -->
		<script type="text/javascript"
			src="../vendor/rs-plugin/revolution-addons/typewriter/js/revolution.addon.typewriter.min.js"></script>

		<!-- Theme Custom -->
		<script src="../js/custom.js"></script>

		<!-- Theme Initialization Files -->
		<script src="../js/theme.init.js"></script>

</body>

</html>